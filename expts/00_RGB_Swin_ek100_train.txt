workers=32
num_gpus=2
experiment_name=Swin_fp6l4h2048_bs32_lr0.001_mixupbackbone-0.1
init_from_model=null
primary_metric=val_mt5r_action_rgb

train.batch_size=16
eval.batch_size=16
train.num_epochs=50
train.use_mixup=true
train.mixup_backbone=true
train.mixup_alpha=0.1

model.modal_dims={rgb:1024}
model.common_dim=1024
model.dropout=0.2
model.common.backbones={rgb: {_target_: torch.nn.Identity}}
model/future_predictor=base_future_predictor
model/CMFP=individual

model.common.share_classifiers=false
model.common.share_predictors=false
model.common.modality_cls=true
model.common.fusion_cls=false

model.common.fp_output_len=1
model.common.fp_inter_dim=2048
model.common.fp_layers=6
model.common.fp_heads=4
model.common.fp_output_attentions=false
model.common.embd_pdrop=0.1
model.common.resid_pdrop=0.1
model.common.attn_pdrop=0.1

opt.lr=0.001
opt.wd=0.000001
opt/optimizer=sgd
opt/scheduler=cosine
opt.optimizer.nesterov=true
opt.warmup.num_epochs=20
opt.scheduler.num_epochs=30
opt.scheduler.eta_min=1e-6

data_train.zero_mask_rate=0.

dataset@dataset_train=epic_kitchens100/train
dataset@dataset_eval=epic_kitchens100/val
dataset.epic_kitchens100.common.label_type=action
dataset.epic_kitchens100.common.sample_strategy=last_clip
dataset.epic_kitchens100.common.tau_a=1
dataset.epic_kitchens100.common.tau_o=10
dataset.epic_kitchens100.common.compute_dataset_stats=true
dataset.epic_kitchens100.common.max_els=null

dataset.epic_kitchens100.common.reader_fn={rgb: {_target_: datasets.reader_fns.EpicRULSTMFeatsReader, lmdb_path: ${dataset.epic_kitchens100.common.rulstm_feats_dir}/rgb_omnivore/}}